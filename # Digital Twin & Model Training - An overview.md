# Digital Twin & Model Training - An overview

This file contains some explanations and examples regarding the digital twin, how to use it to generate usable data, and use said data to train AI models, as well as ways to use trained models on real robot measured data.

## Preparations and set-up

Using the code described in the following sections requires Matlab R2023. The Deep Learning Toolbox will be required to use the AI models. Setting up a [GPU](https://se.mathworks.com/help/parallel-computing/identify-and-select-a-gpu-device.html) in Matlab is highly recommended to perform training operations in reasonable timeframe, and by default the code is written to assume a GPU is available (author's note - this can be changed later on if required).
The code makes widespread use of relative filepaths, and altering the locations and names of files should be done with care. 

The code is entirely geared towards usage for the Hiwonder ArmPi FPV robot arm. Altering it for use with another robot would require a number of corrections, listed as they come up in the following structure overview.

## General structure overview

The digital twin itself is entirely contained in the .slx file main3_armpi_fpv (author's note - placeholder name), which interacts with a subsystem.slx file largely generated by Matlab from the manufacturer-provided URDF file for the Hiwonder ArmPi FPV. Changing robots will require to regenerate a new .slx with smimport, and adjust both the number of motors and the PID parameters in main3_armpi_fpv.slx.

The entire process of generating a trajectory datset with the digital or/and training an AI model on this/a dataset is automated by the main_final.m file. Generation of the dataset is performed inside of the main_final.m whilst the training of the AI model is performed by calling either the  default deep bi-lstm rain_predict.m file or a file given as an argument when running the main_final file, this file should contain the architecture of the model that is to be trained and be made in a similar fashion to the rain_predict.m file in order to guarantee the process remains automatic. The main_final.m is modulable and allows for a number of parameters for the digital twin simulation to be controlled, including types of errors, types of trajectories present in the dataset, size of the dataset, etc... it's possible inputs are described in the code(author's note - to be explained in greater detail). The generated datasets are saved as a structure, containing a cell array of 6*specified length arrays corresponding to individual simulated trajectories with a specific error.

All premade AI model files (rain_predict_lstm.m,optimum_train_predict.m,siamese_model.m,transformermodel.m (author's note - placeholder name) )describe the architecture of a model to be trained and do not need to be directly interacted with as it is expected to call and use them via the main_final.m file. However they can be run alone, they allow the user to specify a saved dataset in the correct format, and can then be run to train a model of the specified format, and then return information on the model's performance (precision, recall, accuracy, f1score, confusion matrix, ROC and AUC curves, and performance/potential overfitting at each iteration during training) . A brief description of the AI architectures in each file will be provided later on.

Besides from this core training aspect, the shape_test.m file (author's note - placeholder name) allows a user to input either a desired 3D trajectory, a desired set of motor commands, or a series of target motor coordinates paired with a duration for each (provided as two .csv files, see examples). The file will then simulate a response to this command, and generate a datapoint for it. If the real response is also provided, it will generate a datapoint for it as well - this can be used to predict the failure state of the robot arm during the provided sample. (author's note - this will be expanded later in a separate file to constitute a proper prediction file, directly paired with the real robot to provide continous monitoring).

## Sample usage - expected results

All files have been provided with default values allowing for test usage simply by running them. 

### Dataset generation

If your Simulink model parameters have the viewer on, any simulation should open a window similar to this one : 

![Sample 3D display](Sample_model_display.PNG)

An empty or incomplete display most likely means a problem with the filepaths inside the "visual" blocks within subsystem.slx.

### Model training

A sample dataset is provided to test model training. Running a model should open a window similar to this one :

![Sample model training](13case_regular_model.PNG)

### Trajectory simulation

Sample trajectories and motor command .csv files are provided. Running shape_test.m should display motor-by-motor comparisons of the simulation and the real trajectory, with multiple figures similar to this one :

![Sample comparison](Sample_comparison.PNG)

## Presentation of the implemented AI architectures:
-rain_predict_lstm.m: a deep-bi-lstm model
-optimum_train_predict.m:  however this file automatically trains a given the model architecutre on different lenght of training elements (for example by cutting down initial 1000 point long trajectories into 10, 100 point trajectories) and proceeds to evaluate these models on different lenghts trajectories from rather large representative datasets to find the best training length/ validation length combination for a given model.
-siamese_model.m: a siamese network model (author's note - this description needs to be expanded)
-transformermodel.m: a slightly modified version of the gated transformer model ([https://se.mathworks.com/help/parallel-computing/identify-and-select-a-gpu-device.html](https://arxiv.org/pdf/2103.14438.pdf)), this model combines two tranformer 'towers' one that analyses the input without the notion of time flow and the second that looks at the input 'in the right order", their respective predictions are then combined in a learned fashion to optimize prediction.

